{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpJd3dlOCStH"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magenta/ddsp/blob/main/ddsp/colab/demos/train_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMqWDc_m6rUC"
      },
      "source": [
        "\n",
        "##### Copyright 2020 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNhgka4UKNjf"
      },
      "outputs": [],
      "source": [
        "# Copyright 2020 Google LLC. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpXo6phTiOQM"
      },
      "source": [
        "# Train a DDSP Autoencoder on GPU\n",
        "\n",
        "This notebook demonstrates how to install the DDSP library and train it for synthesis based on your own data using our command-line scripts. If run inside of Colab, it will automatically use a free Google Cloud GPU.\n",
        "\n",
        "At the end, you'll have a custom-trained checkpoint that you can download to use with the [DDSP Timbre Transfer Colab](https://colab.research.google.com/github/magenta/ddsp/blob/main/ddsp/colab/demos/timbre_transfer.ipynb).\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/ddsp/additive_diagram/ddsp_autoencoder.png\" alt=\"DDSP Autoencoder figure\" width=\"700\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXjcauVRB48S"
      },
      "source": [
        "**Note that we prefix bash commands with a `!` inside of Colab, but you would leave them out if running directly in a terminal.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "VxPuPR0j5Gs7"
      },
      "outputs": [],
      "source": [
        "#@title Install DDSP (using Miniconda)\n",
        "\n",
        "#@markdown Install ddsp in a conda environment with Python 3.9 for compatibility.\n",
        "#@markdown This transfers a lot of data and _should take about 5 minutes_.\n",
        "#@markdown You can ignore warnings.\n",
        "\n",
        "!rm -rf /content/miniconda\n",
        "!curl -L https://repo.anaconda.com/miniconda/Miniconda3-py39_23.11.0-2-Linux-x86_64.sh -o miniconda.sh\n",
        "!chmod +x miniconda.sh\n",
        "!sh miniconda.sh -b -p /content/miniconda\n",
        "!sudo apt-get install -y libportaudio2\n",
        "!/content/miniconda/bin/conda install -y -c conda-forge cudatoolkit=11.2 cudnn=8.1\n",
        "!/content/miniconda/bin/pip install --upgrade pip\n",
        "!/content/miniconda/bin/pip install tensorflow==2.11 tensorflow-probability==0.19.0 tensorflowjs==3.18.0 tensorflow-datasets==4.9.0 tflite-support==0.1.0a1 ddsp[data_preparation]==3.7.0 \"hmmlearn<=0.2.7\"\n",
        "\n",
        "# Initialize global path for using google drive. \n",
        "DRIVE_DIR = ''\n",
        "print('\\nDone installing DDSP in conda environment!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "VxPuPR0j5Gs7"
      },
      "outputs": [],
      "source": [
        "!pip install -qU ddsp[data_preparation]==1.6.3\n",
        "\n",
        "# Initialize global path for using google drive. \n",
        "DRIVE_DIR = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0fVn8yUJl_v"
      },
      "source": [
        "## Setup Google Drive (Optional, Recommeded)\n",
        "\n",
        "This notebook requires uploading audio and saving checkpoints. While you can do this with direct uploads / downloads, it is recommended to connect to your google drive account. This will enable faster file transfer, and regular saving of checkpoints so that you do not lose your work if the colab kernel restarts (common for training more than 12 hours). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6MXUbL6KeMn"
      },
      "source": [
        "#### Login and mount your drive\n",
        "\n",
        "This will require an authentication code. You should then be able to see your drive in the file browser on the left panel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m33xuTjEKazJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4vmxpj1LC7m"
      },
      "source": [
        "#### Set your base directory\n",
        "* In drive, put all of the audio (.wav, .mp3) files with which you would like to train in a single folder.\n",
        " * Typically works well with 10-20 minutes of audio from a single monophonic source (also, one acoustic environment). \n",
        "* Use the file browser in the left panel to find a folder with your audio, right-click **\"Copy Path\", paste below**, and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A0bK6P9DMBTb"
      },
      "outputs": [],
      "source": [
        "#@markdown (ex. `/content/drive/My Drive/...`) Leave blank to skip loading from Drive.\n",
        "DRIVE_DIR = '' #@param {type: \"string\"}\n",
        "\n",
        "import os\n",
        "assert os.path.exists(DRIVE_DIR)\n",
        "print('Drive Folder Exists:', DRIVE_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FELlizMtIxCH"
      },
      "source": [
        "## Make directories to save model and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qd22WxEQI3FV"
      },
      "outputs": [],
      "source": [
        "AUDIO_DIR = 'data/audio'\n",
        "AUDIO_FILEPATTERN = AUDIO_DIR + '/*'\n",
        "!mkdir -p $AUDIO_DIR\n",
        "\n",
        "if DRIVE_DIR:\n",
        "  SAVE_DIR = os.path.join(DRIVE_DIR, 'ddsp-solo-instrument')\n",
        "else:\n",
        "  SAVE_DIR = '/content/models/ddsp-solo-instrument'\n",
        "!mkdir -p \"$SAVE_DIR\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb4YD8woYD1H"
      },
      "source": [
        "## Prepare Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itVKEzF6m3rY"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "if DRIVE_DIR:\n",
        "  mp3_files = glob.glob(os.path.join(DRIVE_DIR, '*.mp3'))\n",
        "  wav_files = glob.glob(os.path.join(DRIVE_DIR, '*.wav'))\n",
        "  audio_files = mp3_files + wav_files\n",
        "else:\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  audio_files = list(uploaded.keys())\n",
        "\n",
        "for fname in audio_files:\n",
        "  target_name = os.path.join(AUDIO_DIR, \n",
        "                             os.path.basename(fname).replace(' ', '_'))\n",
        "  print('Copying {} to {}'.format(fname, target_name))\n",
        "  !cp \"$fname\" $target_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itVKEzF6m3rY"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from ddsp.colab import colab_utils\n",
        "\n",
        "if DRIVE_DIR:\n",
        "  mp3_files = glob.glob(os.path.join(DRIVE_DIR, '*.mp3'))\n",
        "  wav_files = glob.glob(os.path.join(DRIVE_DIR, '*.wav'))\n",
        "  audio_files = mp3_files + wav_files\n",
        "else:\n",
        "  audio_files, _ = colab_utils.upload()\n",
        "\n",
        "for fname in audio_files:\n",
        "  target_name = os.path.join(AUDIO_DIR, \n",
        "                             os.path.basename(fname).replace(' ', '_'))\n",
        "  print('Copying {} to {}'.format(fname, target_name))\n",
        "  !cp \"$fname\" $target_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsnkAHyHVrCW"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "TRAIN_TFRECORD = 'data/train.tfrecord'\n",
        "TRAIN_TFRECORD_FILEPATTERN = TRAIN_TFRECORD + '*'\n",
        "\n",
        "# Copy dataset from drive if dataset has already been created.\n",
        "drive_data_dir = os.path.join(DRIVE_DIR, 'data') \n",
        "drive_dataset_files = glob.glob(drive_data_dir + '/*')\n",
        "\n",
        "if DRIVE_DIR and len(drive_dataset_files) > 0:\n",
        "  !cp \"$drive_data_dir\"/* data/\n",
        "\n",
        "else:\n",
        "  # Make a new dataset.\n",
        "  if not glob.glob(AUDIO_FILEPATTERN):\n",
        "    raise ValueError('No audio files found. Please use the previous cell to '\n",
        "                    'upload.')\n",
        "\n",
        "  cmd = (\n",
        "      \"unset PYTHONPATH PYTHONHOME && \"\n",
        "      \"export LD_LIBRARY_PATH=/content/miniconda/lib:$LD_LIBRARY_PATH && \"\n",
        "      \"/content/miniconda/bin/ddsp_prepare_tfrecord \"\n",
        "      f\"--input_audio_filepatterns={AUDIO_FILEPATTERN} \"\n",
        "      f\"--output_tfrecord_path={TRAIN_TFRECORD} \"\n",
        "      \"--num_shards=10 \"\n",
        "      \"--alsologtostderr\"\n",
        "  )\n",
        "  !{cmd}\n",
        "\n",
        "  # Copy dataset to drive for safe-keeping.\n",
        "  if DRIVE_DIR:\n",
        "    !mkdir \"$drive_data_dir\"/\n",
        "    print('Saving to {}'.format(drive_data_dir))\n",
        "    !cp $TRAIN_TFRECORD_FILEPATTERN \"$drive_data_dir\"/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsnkAHyHVrCW"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "TRAIN_TFRECORD = 'data/train.tfrecord'\n",
        "TRAIN_TFRECORD_FILEPATTERN = TRAIN_TFRECORD + '*'\n",
        "\n",
        "# Copy dataset from drive if dataset has already been created.\n",
        "drive_data_dir = os.path.join(DRIVE_DIR, 'data') \n",
        "drive_dataset_files = glob.glob(drive_data_dir + '/*')\n",
        "\n",
        "if DRIVE_DIR and len(drive_dataset_files) > 0:\n",
        "  !cp \"$drive_data_dir\"/* data/\n",
        "\n",
        "else:\n",
        "  # Make a new dataset.\n",
        "  if not glob.glob(AUDIO_FILEPATTERN):\n",
        "    raise ValueError('No audio files found. Please use the previous cell to '\n",
        "                    'upload.')\n",
        "\n",
        "  !ddsp_prepare_tfrecord \\\n",
        "    --input_audio_filepatterns=$AUDIO_FILEPATTERN \\\n",
        "    --output_tfrecord_path=$TRAIN_TFRECORD \\\n",
        "    --num_shards=10 \\\n",
        "    --alsologtostderr\n",
        "\n",
        "  # Copy dataset to drive for safe-keeping.\n",
        "  if DRIVE_DIR:\n",
        "    !mkdir \"$drive_data_dir\"/\n",
        "    print('Saving to {}'.format(drive_data_dir))\n",
        "    !cp $TRAIN_TFRECORD_FILEPATTERN \"$drive_data_dir\"/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Bp_c8P0xApY6"
      },
      "outputs": [],
      "source": [
        "#@title Save dataset statistics\n",
        "#@markdown Writes a script and runs it in the conda environment.\n",
        "\n",
        "SCRIPT = r'''\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import ddsp.training\n",
        "from ddsp.training import postprocessing\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "file_pattern = sys.argv[1]\n",
        "save_dir = sys.argv[2]\n",
        "\n",
        "data_provider = ddsp.training.data.TFRecordProvider(file_pattern)\n",
        "ds_stats = postprocessing.compute_dataset_statistics(\n",
        "    data_provider, batch_size=1, power_frame_size=256)\n",
        "\n",
        "pickle_path = os.path.join(save_dir, 'dataset_statistics.pkl')\n",
        "with tf.io.gfile.GFile(pickle_path, 'wb') as f:\n",
        "    pickle.dump(ds_stats, f)\n",
        "print(f'Saved dataset statistics to: {pickle_path}')\n",
        "'''\n",
        "\n",
        "with open('/content/save_stats.py', 'w') as f:\n",
        "  f.write(SCRIPT)\n",
        "\n",
        "PICKLE_FILE_PATH = os.path.join(SAVE_DIR, 'dataset_statistics.pkl')\n",
        "cmd = (\n",
        "    \"unset PYTHONPATH PYTHONHOME && \"\n",
        "    \"export LD_LIBRARY_PATH=/content/miniconda/lib:$LD_LIBRARY_PATH && \"\n",
        "    \"/content/miniconda/bin/python /content/save_stats.py \"\n",
        "    f\"'{TRAIN_TFRECORD_FILEPATTERN}' '{SAVE_DIR}'\"\n",
        ")\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp_c8P0xApY6"
      },
      "outputs": [],
      "source": [
        "from ddsp.colab import colab_utils\n",
        "import ddsp.training\n",
        "\n",
        "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
        "dataset = data_provider.get_dataset(shuffle=False)\n",
        "PICKLE_FILE_PATH = os.path.join(SAVE_DIR, 'dataset_statistics.pkl')\n",
        "\n",
        "_ = colab_utils.save_dataset_statistics(data_provider, PICKLE_FILE_PATH, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dA-FOmRgYdpZ"
      },
      "outputs": [],
      "source": [
        "#@title View dataset example\n",
        "#@markdown Load one example from the dataset and display it.\n",
        "\n",
        "# --- Write and run script in conda env to extract example ---\n",
        "SCRIPT = r'''\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import ddsp.training\n",
        "\n",
        "file_pattern = sys.argv[1]\n",
        "output_dir = sys.argv[2]\n",
        "\n",
        "data_provider = ddsp.training.data.TFRecordProvider(file_pattern)\n",
        "dataset = data_provider.get_dataset(shuffle=False)\n",
        "\n",
        "try:\n",
        "    ex = next(iter(dataset))\n",
        "except StopIteration:\n",
        "    raise ValueError(\n",
        "        'TFRecord contains no examples. Please try re-running the pipeline '\n",
        "        'with different audio file(s).')\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for key in ex:\n",
        "    val = ex[key]\n",
        "    if hasattr(val, 'numpy'):\n",
        "        val = val.numpy()\n",
        "    np.save(os.path.join(output_dir, f'{key}.npy'), np.array(val))\n",
        "print('Saved dataset example to:', output_dir)\n",
        "'''\n",
        "\n",
        "with open('/content/load_example.py', 'w') as f:\n",
        "  f.write(SCRIPT)\n",
        "\n",
        "cmd = (\n",
        "    \"unset PYTHONPATH PYTHONHOME && \"\n",
        "    \"export LD_LIBRARY_PATH=/content/miniconda/lib:$LD_LIBRARY_PATH && \"\n",
        "    \"/content/miniconda/bin/python /content/load_example.py \"\n",
        "    f\"'{TRAIN_TFRECORD_FILEPATTERN}' '/content/example_output'\"\n",
        ")\n",
        "!{cmd}\n",
        "\n",
        "# --- Display results in Colab kernel ---\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import base64\n",
        "import io\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from scipy.io import wavfile\n",
        "from scipy import signal as scipy_signal\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "\n",
        "\n",
        "def play(array_of_floats, sample_rate=SAMPLE_RATE):\n",
        "  \"\"\"Play audio in colab using HTML5 audio widget.\"\"\"\n",
        "  if len(array_of_floats.shape) == 2:\n",
        "    array_of_floats = array_of_floats[0]\n",
        "  normalizer = float(np.iinfo(np.int16).max)\n",
        "  array_of_ints = np.array(\n",
        "      np.asarray(array_of_floats) * normalizer, dtype=np.int16)\n",
        "  memfile = io.BytesIO()\n",
        "  wavfile.write(memfile, sample_rate, array_of_ints)\n",
        "  html = \"\"\"<audio controls>\n",
        "              <source controls src=\"data:audio/wav;base64,{base64_wavfile}\"\n",
        "              type=\"audio/wav\" />\n",
        "              Your browser does not support the audio element.\n",
        "            </audio>\"\"\"\n",
        "  html = html.format(\n",
        "      base64_wavfile=base64.b64encode(memfile.getvalue()).decode('ascii'))\n",
        "  memfile.close()\n",
        "  display.display(display.HTML(html))\n",
        "\n",
        "\n",
        "def specplot(audio, vmin=-5, vmax=1, rotate=True, size=512 + 256):\n",
        "  \"\"\"Plot the log magnitude spectrogram of audio.\"\"\"\n",
        "  if len(audio.shape) == 2:\n",
        "    audio = audio[0]\n",
        "  f, t, Sxx = scipy_signal.stft(audio, fs=SAMPLE_RATE, nperseg=size,\n",
        "                                 noverlap=size * 3 // 4)\n",
        "  logmag = np.log10(np.abs(Sxx) + 1e-7)\n",
        "  if rotate:\n",
        "    logmag = np.flipud(logmag)\n",
        "  plt.matshow(logmag, vmin=vmin, vmax=vmax, cmap=plt.cm.magma, aspect='auto')\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Frequency')\n",
        "\n",
        "\n",
        "# Load and display\n",
        "audio = np.load('/content/example_output/audio.npy')\n",
        "f0_hz = np.load('/content/example_output/f0_hz.npy')\n",
        "loudness_db = np.load('/content/example_output/loudness_db.npy')\n",
        "f0_confidence = np.load('/content/example_output/f0_confidence.npy')\n",
        "\n",
        "specplot(audio)\n",
        "play(audio)\n",
        "\n",
        "f, ax = plt.subplots(3, 1, figsize=(14, 4))\n",
        "x = np.linspace(0, 4.0, len(loudness_db))\n",
        "ax[0].set_ylabel('loudness_db')\n",
        "ax[0].plot(x, loudness_db)\n",
        "ax[1].set_ylabel('F0_Hz')\n",
        "ax[1].set_xlabel('seconds')\n",
        "ax[1].plot(x, f0_hz)\n",
        "ax[2].set_ylabel('F0_confidence')\n",
        "ax[2].set_xlabel('seconds')\n",
        "ax[2].plot(x, f0_confidence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA-FOmRgYdpZ"
      },
      "outputs": [],
      "source": [
        "from ddsp.colab import colab_utils\n",
        "import ddsp.training\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
        "dataset = data_provider.get_dataset(shuffle=False)\n",
        "\n",
        "try:\n",
        "  ex = next(iter(dataset))\n",
        "except StopIteration:\n",
        "  raise ValueError(\n",
        "      'TFRecord contains no examples. Please try re-running the pipeline with '\n",
        "      'different audio file(s).')\n",
        "\n",
        "colab_utils.specplot(ex['audio'])\n",
        "colab_utils.play(ex['audio'])\n",
        "\n",
        "f, ax = plt.subplots(3, 1, figsize=(14, 4))\n",
        "x = np.linspace(0, 4.0, 1000)\n",
        "ax[0].set_ylabel('loudness_db')\n",
        "ax[0].plot(x, ex['loudness_db'])\n",
        "ax[1].set_ylabel('F0_Hz')\n",
        "ax[1].set_xlabel('seconds')\n",
        "ax[1].plot(x, ex['f0_hz'])\n",
        "ax[2].set_ylabel('F0_confidence')\n",
        "ax[2].set_xlabel('seconds')\n",
        "ax[2].plot(x, ex['f0_confidence'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gvXBa7PbuyY"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "We will now train a \"solo instrument\" model. This means the model is conditioned only on the fundamental frequency (f0) and loudness with no instrument ID or latent timbre feature. If you uploaded audio of multiple instruemnts, the neural network you train will attempt to model all timbres, but will likely associate certain timbres with different f0 and loudness conditions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpwQkSIKjEMZ"
      },
      "source": [
        "First, let's start up a [TensorBoard](https://www.tensorflow.org/tensorboard) to monitor our loss as training proceeds. \n",
        "\n",
        "Initially, TensorBoard will report `No dashboards are active for the current data set.`, but once training begins, the dashboards should appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2lx7yJneUXT"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "import tensorboard as tb\n",
        "tb.notebook.start('--logdir \"{}\"'.format(SAVE_DIR))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poKO-mZEGYXZ"
      },
      "outputs": [],
      "source": [
        "cmd = (\n",
        "    \"unset PYTHONPATH PYTHONHOME && \"\n",
        "    \"export LD_LIBRARY_PATH=/content/miniconda/lib:$LD_LIBRARY_PATH && \"\n",
        "    \"/content/miniconda/bin/ddsp_run \"\n",
        "    \"--mode=train \"\n",
        "    \"--alsologtostderr \"\n",
        "    f\"--save_dir='{SAVE_DIR}' \"\n",
        "    \"--gin_file=models/solo_instrument.gin \"\n",
        "    \"--gin_file=datasets/tfrecord.gin \"\n",
        "    f\"--gin_param=\\\"TFRecordProvider.file_pattern='{TRAIN_TFRECORD_FILEPATTERN}'\\\" \"\n",
        "    \"--gin_param=\\\"batch_size=16\\\" \"\n",
        "    \"--gin_param=\\\"train_util.train.num_steps=30000\\\" \"\n",
        "    \"--gin_param=\\\"train_util.train.steps_per_save=300\\\" \"\n",
        "    \"--gin_param=\\\"trainers.Trainer.checkpoints_to_keep=10\\\"\"\n",
        ")\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poKO-mZEGYXZ"
      },
      "outputs": [],
      "source": [
        "!ddsp_run \\\n",
        "  --mode=train \\\n",
        "  --alsologtostderr \\\n",
        "  --save_dir=\"$SAVE_DIR\" \\\n",
        "  --gin_file=models/solo_instrument.gin \\\n",
        "  --gin_file=datasets/tfrecord.gin \\\n",
        "  --gin_param=\"TFRecordProvider.file_pattern='$TRAIN_TFRECORD_FILEPATTERN'\" \\\n",
        "  --gin_param=\"batch_size=16\" \\\n",
        "  --gin_param=\"train_util.train.num_steps=30000\" \\\n",
        "  --gin_param=\"train_util.train.steps_per_save=300\" \\\n",
        "  --gin_param=\"trainers.Trainer.checkpoints_to_keep=10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OQ5PPDZVzgFR"
      },
      "outputs": [],
      "source": [
        "#@title Resynthesis\n",
        "#@markdown Check how well the model reconstructs the training data.\n",
        "\n",
        "# --- Write and run resynthesis script in conda env ---\n",
        "SCRIPT = r'''\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import ddsp.training\n",
        "import gin\n",
        "\n",
        "file_pattern = sys.argv[1]\n",
        "save_dir = sys.argv[2]\n",
        "output_dir = sys.argv[3]\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "data_provider = ddsp.training.data.TFRecordProvider(file_pattern)\n",
        "dataset = data_provider.get_batch(batch_size=1, shuffle=False)\n",
        "\n",
        "try:\n",
        "    batch = next(iter(dataset))\n",
        "except:\n",
        "    raise ValueError(\n",
        "        'TFRecord contains no examples. Please try re-running the pipeline '\n",
        "        'with different audio file(s).')\n",
        "\n",
        "# Parse the gin config.\n",
        "gin_file = os.path.join(save_dir, 'operative_config-0.gin')\n",
        "gin.parse_config_file(gin_file)\n",
        "\n",
        "# Load model\n",
        "model = ddsp.training.models.Autoencoder()\n",
        "model.restore(save_dir)\n",
        "\n",
        "# Resynthesize audio.\n",
        "outputs = model(batch, training=False)\n",
        "audio_gen = model.get_audio_from_outputs(outputs)\n",
        "audio = batch['audio']\n",
        "\n",
        "# Convert to numpy\n",
        "if hasattr(audio_gen, 'numpy'):\n",
        "    audio_gen = audio_gen.numpy()\n",
        "if hasattr(audio, 'numpy'):\n",
        "    audio = audio.numpy()\n",
        "\n",
        "np.save(os.path.join(output_dir, 'audio_gen.npy'), np.array(audio_gen))\n",
        "np.save(os.path.join(output_dir, 'audio_orig.npy'), np.array(audio))\n",
        "print('Saved resynthesis outputs to:', output_dir)\n",
        "'''\n",
        "\n",
        "with open('/content/resynthesize.py', 'w') as f:\n",
        "  f.write(SCRIPT)\n",
        "\n",
        "cmd = (\n",
        "    \"unset PYTHONPATH PYTHONHOME && \"\n",
        "    \"export LD_LIBRARY_PATH=/content/miniconda/lib:$LD_LIBRARY_PATH && \"\n",
        "    \"/content/miniconda/bin/python /content/resynthesize.py \"\n",
        "    f\"'{TRAIN_TFRECORD_FILEPATTERN}' '{SAVE_DIR}' '/content/resynth_output'\"\n",
        ")\n",
        "!{cmd}\n",
        "\n",
        "# --- Display results ---\n",
        "import numpy as np\n",
        "\n",
        "audio_gen = np.load('/content/resynth_output/audio_gen.npy')\n",
        "audio_orig = np.load('/content/resynth_output/audio_orig.npy')\n",
        "\n",
        "print('Original Audio')\n",
        "specplot(audio_orig)\n",
        "play(audio_orig)\n",
        "\n",
        "print('Resynthesis')\n",
        "specplot(audio_gen)\n",
        "play(audio_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ5PPDZVzgFR"
      },
      "outputs": [],
      "source": [
        "from ddsp.colab.colab_utils import play, specplot\n",
        "import ddsp.training\n",
        "import gin\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
        "dataset = data_provider.get_batch(batch_size=1, shuffle=False)\n",
        "\n",
        "try:\n",
        "  batch = next(iter(dataset))\n",
        "except OutOfRangeError:\n",
        "  raise ValueError(\n",
        "      'TFRecord contains no examples. Please try re-running the pipeline with '\n",
        "      'different audio file(s).')\n",
        "\n",
        "# Parse the gin config.\n",
        "gin_file = os.path.join(SAVE_DIR, 'operative_config-0.gin')\n",
        "gin.parse_config_file(gin_file)\n",
        "\n",
        "# Load model\n",
        "model = ddsp.training.models.Autoencoder()\n",
        "model.restore(SAVE_DIR)\n",
        "\n",
        "# Resynthesize audio.\n",
        "outputs = model(batch, training=False)\n",
        "audio_gen = model.get_audio_from_outputs(outputs)\n",
        "audio = batch['audio']\n",
        "\n",
        "print('Original Audio')\n",
        "specplot(audio)\n",
        "play(audio)\n",
        "\n",
        "print('Resynthesis')\n",
        "specplot(audio_gen)\n",
        "play(audio_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WDiCyXP0tNE"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "CHECKPOINT_ZIP = 'my_solo_instrument.zip'\n",
        "latest_checkpoint_fname = os.path.basename(tf.train.latest_checkpoint(SAVE_DIR))\n",
        "!cd \"$SAVE_DIR\" && zip $CHECKPOINT_ZIP $latest_checkpoint_fname* operative_config-0.gin dataset_statistics.pkl\n",
        "!cp \"$SAVE_DIR/$CHECKPOINT_ZIP\" ./\n",
        "files.download(CHECKPOINT_ZIP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WDiCyXP0tNE"
      },
      "outputs": [],
      "source": [
        "from ddsp.colab import colab_utils\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "CHECKPOINT_ZIP = 'my_solo_instrument.zip'\n",
        "latest_checkpoint_fname = os.path.basename(tf.train.latest_checkpoint(SAVE_DIR))\n",
        "!cd \"$SAVE_DIR\" && zip $CHECKPOINT_ZIP $latest_checkpoint_fname* operative_config-0.gin dataset_statistics.pkl\n",
        "!cp \"$SAVE_DIR/$CHECKPOINT_ZIP\" ./\n",
        "colab_utils.download(CHECKPOINT_ZIP)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hMqWDc_m6rUC"
      ],
      "name": "train_autoencoder.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
